{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectors(file):\n",
    "    dct = {}\n",
    "    with open(file, 'r', encoding = 'utf-8') as rfile:\n",
    "        for line in rfile:\n",
    "            line = line.split()\n",
    "            dct[line[0]] = np.asarray(line[1:], dtype='float32')\n",
    "    return(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wv(word,dct):\n",
    "    if word in dct:\n",
    "        vector = dct[word]\n",
    "    else:\n",
    "        vector = np.random.uniform(-1,1,(100,)).astype(np.float32)\n",
    "    return(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_prepare(file,dct):\n",
    "    count = 0\n",
    "    #creating X: number_of_samples x 3(pivot,comparison,feature) x 100(word_vector length)\n",
    "    X = np.zeros((0,3,100), dtype=np.float)\n",
    "    y = np.zeros((0,2), dtype=np.bool)\n",
    "    count = 0\n",
    "    with open(file,'r',encoding= 'utf-8') as rfile:\n",
    "        for line in rfile:\n",
    "            count += 1\n",
    "            line = line.rstrip().split(',')\n",
    "            words = line[:3]\n",
    "            answer = line[3]\n",
    "\n",
    "            sample = np.zeros((0,100), dtype=np.float)\n",
    "            for word in words:\n",
    "                sample = np.append(sample,[wv(word,dct)], axis = 0)\n",
    "            X = np.append(X,[sample], axis = 0)\n",
    "\n",
    "            if answer == '1':\n",
    "                y = np.append(y,[[0,1]], axis = 0)\n",
    "            else:\n",
    "                y = np.append(y,[[1,0]], axis = 0)\n",
    "            \n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def answers(dct,model):\n",
    "    answer_file = 'res/answer.txt'\n",
    "    val_file = 'ref/validation.txt'\n",
    "    count = 0\n",
    "    with open(answer_file,'w', encoding = 'utf-8') as ans_file:\n",
    "        with open(val_file,'r',encoding = 'utf-8') as rfile:\n",
    "            for line in rfile:\n",
    "                count += 1\n",
    "                if count >= 1723:\n",
    "                    line = line.rstrip().split(',')\n",
    "                    words = line[:3]\n",
    "                    sample = np.zeros((0,100), dtype=np.float)\n",
    "                    for word in words:\n",
    "                        sample = np.append(sample,[wv(word,dct)], axis = 0)\n",
    "                    sample = np.expand_dims(sample, axis = 0)\n",
    "                    output = model.predict(sample)\n",
    "                    answer = np.argmax(output) #index of the higher probability\n",
    "                    ans_file.write('{},{},{},{}\\n'.format(words[0],words[1],words[2],answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%time dct = vectors('glove/glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.26 s\n"
     ]
    }
   ],
   "source": [
    "#%time X,y = data_prepare('train/train.txt',dct)\n",
    "\n",
    "%time X,y = data_prepare('ref/validation.txt',dct)\n",
    "X_tn = X[:-1000]\n",
    "X_ts = X[-1000:]\n",
    "y_tn = y[:-1000]\n",
    "y_ts = y[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(1024, input_shape=(3, 100)))\n",
    "model.add(Dropout(0.2))\n",
    "for i in range(1):\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, verbose=1, save_best_only=True, mode='max', monitor='val_acc')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "with open(\"model.json\", \"w\") as text_file:\n",
    "    text_file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: val_acc improved from -inf to 0.60600, saving model to weights-improvement-00.hdf5\n",
      "Epoch 00001: val_acc improved from 0.60600 to 0.66700, saving model to weights-improvement-01.hdf5\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 00004: val_acc improved from 0.66700 to 0.68700, saving model to weights-improvement-04.hdf5\n",
      "Epoch 00005: val_acc did not improve\n",
      "Epoch 00006: val_acc did not improve\n",
      "Epoch 00007: val_acc did not improve\n",
      "Epoch 00008: val_acc improved from 0.68700 to 0.70100, saving model to weights-improvement-08.hdf5\n",
      "Epoch 00009: val_acc improved from 0.70100 to 0.70400, saving model to weights-improvement-09.hdf5\n",
      "Epoch 00010: val_acc did not improve\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 00012: val_acc improved from 0.70400 to 0.70600, saving model to weights-improvement-12.hdf5\n",
      "Epoch 00013: val_acc improved from 0.70600 to 0.71800, saving model to weights-improvement-13.hdf5\n",
      "Epoch 00014: val_acc did not improve\n",
      "Epoch 00015: val_acc improved from 0.71800 to 0.72500, saving model to weights-improvement-15.hdf5\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 00017: val_acc did not improve\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 00019: val_acc improved from 0.72500 to 0.73100, saving model to weights-improvement-19.hdf5\n",
      "Wall time: 9min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x8100b3c8>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "% time model.fit(X_tn, y_tn, epochs=20, batch_size=16, validation_data=(X_ts, y_ts), verbose=0, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights('73_my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers(dct,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(triple,dct):\n",
    "    x = np.zeros((0,3,100), dtype=np.float)\n",
    "    sample = np.zeros((0,100), dtype=np.float)\n",
    "    for word in triple:\n",
    "        sample = np.append(sample,[wv(word,dct)], axis = 0)\n",
    "    #print(sample.shape)\n",
    "    x = np.append(x,[sample], axis = 0)\n",
    "    #print(x.shape)\n",
    "    #print(x)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    preds = preds.tolist()\n",
    "    answer = preds[1]\n",
    "    #answer = np.argmax(preds)\n",
    "    #print(answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "from nltk.corpus import brown\n",
    "from nltk import bigrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(bigrams(list(brown.words())))\n",
    "\n",
    "def get_brown_bigram_cooccurence(w1, w2, c=c):\n",
    "    return c[(w1,w2)]\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading w2v model...\n",
      "w2v model is loaded after 0:02:47.697484\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "print('Loading w2v model...')\n",
    "wvmodel = KeyedVectors.load_word2vec_format('w2vmodels/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "wvmodel.init_sims(replace=True)\n",
    "print('w2v model is loaded after', datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Just to make it a bit more readable\n",
    "WN_NOUN = 'n'\n",
    "WN_VERB = 'v'\n",
    "WN_ADJECTIVE = 'a'\n",
    "WN_ADJECTIVE_SATELLITE = 's'\n",
    "WN_ADVERB = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert(word, from_pos, to_pos):\n",
    "    \"\"\" Transform words given from/to POS tags \"\"\"\n",
    "\n",
    "    synsets = wn.synsets(word, pos=from_pos)\n",
    "\n",
    "    # Word not found\n",
    "    if not synsets:\n",
    "        return []\n",
    "\n",
    "    # Get all lemmas of the word (consider 'a'and 's' equivalent)\n",
    "    lemmas = [l for s in synsets\n",
    "                for l in s.lemmas()\n",
    "                if s.name().split('.')[1] == from_pos\n",
    "                    or from_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)\n",
    "                        and s.name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)]\n",
    "\n",
    "    # Get related forms\n",
    "    derivationally_related_forms = [(l, l.derivationally_related_forms()) for l in lemmas]\n",
    "\n",
    "    # filter only the desired pos (consider 'a' and 's' equivalent)\n",
    "    related_noun_lemmas = [l for drf in derivationally_related_forms\n",
    "                             for l in drf[1]\n",
    "                             if l.synset().name().split('.')[1] == to_pos\n",
    "                                or to_pos in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)\n",
    "                                    and l.synset.name().split('.')[1] in (WN_ADJECTIVE, WN_ADJECTIVE_SATELLITE)]\n",
    "\n",
    "    # Extract the words from the lemmas\n",
    "    words = [l.name() for l in related_noun_lemmas]\n",
    "    len_words = len(words)\n",
    "\n",
    "    # Build the result in the form of a list containing tuples (word, probability)\n",
    "    result = [(w, float(words.count(w))/len_words) for w in set(words)]\n",
    "    result.sort(key=lambda w: -w[1])\n",
    "\n",
    "    # return all the possibilities sorted by probability\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wordnet_features(triples):\n",
    "    X_orig = list()\n",
    "    for triple in triples:\n",
    "        norm_third = triple[2]\n",
    "        try:\n",
    "            first = wn.synsets(triple[0])[0]\n",
    "            second = wn.synsets(triple[1])[0]\n",
    "            try:\n",
    "                third_orig = wn.synsets(norm_third)[0]\n",
    "            except IndexError:\n",
    "                # print(wn.synsets(norm_third), norm_third)\n",
    "                X_orig.append('no_stuff')\n",
    "                continue\n",
    "            if third_orig.pos() != 'n':\n",
    "                try:\n",
    "                    third_n = convert(norm_third, third_orig.pos(), WN_NOUN)[0][0]\n",
    "                except IndexError:\n",
    "                    # print(convert(norm_third, third_orig.pos(), WN_NOUN), norm_third, third_orig.pos())\n",
    "                    X_orig.append('no_stuff')\n",
    "                    continue\n",
    "            else:\n",
    "                third_n = third_orig.name().split('.')[0]\n",
    "                #print(third_orig.name().split('.')[0])\n",
    "            third = wn.synsets(third_n)[0]\n",
    "            dist_one = wn.wup_similarity(first, third)\n",
    "            dist_two = wn.wup_similarity(second, third)\n",
    "            dist_bet = wn.wup_similarity(first, second)\n",
    "            path_one = first.path_similarity(third)\n",
    "            path_two = second.path_similarity(third)\n",
    "            path_bet = first.path_similarity(second)\n",
    "            res_one = first.res_similarity(third, brown_ic)\n",
    "            res_two = second.res_similarity(third, brown_ic)\n",
    "            #res_bet = first.res_similarity(second, brown_ic)\n",
    "            lin_one = first.lin_similarity(third, brown_ic)\n",
    "            lin_two = second.lin_similarity(third, brown_ic)\n",
    "            lin_bet = first.lin_similarity(second, brown_ic)\n",
    "            lch_one = first.lch_similarity(third, brown_ic)\n",
    "            lch_two = second.lch_similarity(third, brown_ic)\n",
    "            lch_bet = first.lch_similarity(second, brown_ic)\n",
    "            vector = [dist_one, dist_two, path_one, path_two, res_one, res_two, lin_one, lin_two, lch_one, lch_two, \\\n",
    "                      dist_bet, path_bet, lin_bet, lch_bet]\n",
    "            if None in vector:\n",
    "                print(triple, vector, first, second, first.path_similarity(third))\n",
    "            X_orig.append(vector)\n",
    "        except IndexError as e:\n",
    "            print(e)\n",
    "\n",
    "    #print(np.array([row for row in X_orig if row != 'no_stuff']))\n",
    "    good_only = np.mean(np.array([row for row in X_orig if row != 'no_stuff']), axis=0)\n",
    "    #print(good_only.tolist())\n",
    "    X_orig_with_means = []\n",
    "    for row in X_orig:\n",
    "        if row == 'no_stuff':\n",
    "            X_orig_with_means.append(good_only.tolist())\n",
    "        else:\n",
    "            X_orig_with_means.append(row)\n",
    "\n",
    "    X = np.array(X_orig_with_means, dtype=float)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X_orig_with_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_triples(data_set):\n",
    "    \"\"\"Парсит триплы данных в массив кортежей\"\"\"\n",
    "    data_set = open(data_set, 'r', encoding='utf-8')\n",
    "    triples = list()\n",
    "    for triple in data_set:\n",
    "        triple = triple.split(',')\n",
    "        word1 = triple[0]\n",
    "        word2 = triple[1]\n",
    "        feature = triple[2]\n",
    "        triples.append((word1, word2, feature))\n",
    "    data_set.close()\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_truth(data_set):\n",
    "    \"\"\"Достает правильные ответы из данных = truth\"\"\"\n",
    "    data_set = open(data_set, 'r', encoding='utf-8')\n",
    "    truth = list()\n",
    "    for triple in data_set:\n",
    "        triple = triple.split(',')\n",
    "        answer = triple[3]\n",
    "        truth.append(answer)\n",
    "    data_set.close()\n",
    "    return truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_features(data_set):\n",
    "    \"\"\"Считает similarity по гугл-n-грамам для всех пар в трипле.\n",
    "    Если такого слова нет в n-грамах, пишет 'not_in_voc'ю\n",
    "    Результат кладет в список списков - так и подается на обучение классификатору.\"\"\"\n",
    "    features_data = list()\n",
    "    triples = split_triples(data_set)\n",
    "    wordndet_features = get_wordnet_features(triples)\n",
    "    n = 0\n",
    "    for triple in triples:\n",
    "        word1 = triple[0]\n",
    "        word2 = triple[1]\n",
    "        feature = triple[2]\n",
    "        #lstm prediction as feature\n",
    "        lstm_predict = predict(triple,dct)\n",
    "        #coocurence in brown corpus as feature\n",
    "        coc_one = get_brown_bigram_cooccurence(word1, feature)\n",
    "        coc_two = get_brown_bigram_cooccurence(word2, feature)\n",
    "        #most important feature\n",
    "        #important_features = [len(word1), len(word2), len(feature),len(word1)/len(word2), len(word1)/len(feature), len(word2)/len(feature)]\n",
    "        #vector similarity as feature\n",
    "        try:\n",
    "            word1_and_feature_sim = wvmodel.wv.similarity(word1, feature)\n",
    "        except KeyError:\n",
    "            word1_and_feature_sim = 'not_in_voc'\n",
    "        try:\n",
    "            word2_and_feature_sim = wvmodel.wv.similarity(word2, feature)\n",
    "        except KeyError:\n",
    "            word2_and_feature_sim = 'not_in_voc'\n",
    "        try:\n",
    "            word1_and_word2_sim = wvmodel.wv.similarity(word1, word2)\n",
    "        except KeyError:\n",
    "            word1_and_word2_sim = 'not_in_voc'\n",
    "        features_data.append([word1_and_feature_sim, word2_and_feature_sim, word1_and_word2_sim,lstm_predict, coc_one, coc_two] + wordndet_features[n])\n",
    "        n += 1\n",
    "    return features_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_average_similarity(similarity_data):\n",
    "    \"\"\"Считает среднюю similarity по гугл-n-грамам по всем данным\"\"\"\n",
    "    similarity_sum = 0\n",
    "    norm_sim_amount = 0\n",
    "    for feature_set in similarity_data:\n",
    "        for feature in feature_set[:3]:\n",
    "            if feature != 'not_in_voc':\n",
    "                similarity_sum += feature\n",
    "                norm_sim_amount += 1\n",
    "    average_similarity = similarity_sum / norm_sim_amount\n",
    "    return average_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_similarity_data(data_set):\n",
    "    \"\"\"Заменяет 'not_in_voc' на среднюю similarity в данных\"\"\"\n",
    "    all_features_data = get_all_features(data_set)\n",
    "    average_similarity = calculate_average_similarity(all_features_data)\n",
    "    print('\\nAverage similarity for {0} is'.format(data_set), average_similarity, '\\n')\n",
    "    similarity_data_clean = list()\n",
    "    for feature_set in all_features_data:\n",
    "        feature_set_clean = [average_similarity if x == 'not_in_voc' else x for x in feature_set]\n",
    "        similarity_data_clean.append(feature_set_clean)\n",
    "    return similarity_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(train_set):\n",
    "    # загружаем данные (обучение + тест в одном файле)\n",
    "    # собираем фичи - X\n",
    "    data = clean_similarity_data(train_set)\n",
    "    # делим данные - первые 1772 на train, последние 1000 - на test\n",
    "    X_train = data[:-1000]\n",
    "    X_test = data[-1000:]\n",
    "\n",
    "    # собираем ответы - y\n",
    "    y = [int(x.split('\\n')[0]) for x in get_truth(train_set)]\n",
    "    # делим ответы - первые 1772 train, последние 1000 - test\n",
    "    y_train = y[:-1000]\n",
    "    y_test = y[-1000:]\n",
    "\n",
    "    # делим все данные на train и test так, чтобы в test было 1000\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000, random_state=33)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_regression_print_results(X_train, X_test, y_train, y_test, seed, C):\n",
    "\n",
    "    # тренируем логистическую регрессию\n",
    "    clf_logreg = linear_model.LogisticRegression(random_state=seed, C=C)\n",
    "    clf_logreg.fit(X_train, y_train)\n",
    "\n",
    "    # оцениваем результат\n",
    "    predictions = clf_logreg.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    # print('f1: ' + str(f1_score(y_test, predictions))) - эта хрень не то показывает\n",
    "\n",
    "    print('X_train length:', len(X_train))\n",
    "    print('y_test lenght:', len(y_test), '\\npredictions length:', len(predictions))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results_in_file(predictions, y_test):\n",
    "    # записываем результат в нужную папку для запуска официального evaluation скрипта\n",
    "    res = open('./trial/res/answer.txt', 'w', encoding='utf-8')\n",
    "    truth_res = open('./trial/ref/truth.txt', 'w', encoding='utf-8')\n",
    "    print('\\nWriting results to \"answer.txt\".')\n",
    "    triples = split_triples(train_set)[-1000:]\n",
    "    for i in range(len(predictions)):\n",
    "        w1 = triples[i][0]\n",
    "        w2 = triples[i][1]\n",
    "        feat = triples[i][2]\n",
    "        result = predictions[i]\n",
    "        truth = y_test[i]\n",
    "        res.write(w1 + ',' + w2 + ',' + feat + ',' + str(result) + '\\n')\n",
    "        truth_res.write(w1 + ',' + w2 + ',' + feat + ',' + str(truth) + '\\n')\n",
    "    res.close()\n",
    "    truth_res.close()\n",
    "    print('\\nThe results are written to \"answer.txt\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average similarity for ./training/validation.txt is 0.287926773692 \n",
      "\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "train_set = './training/validation.txt'\n",
    "\n",
    "%time X_train, X_test, y_train, y_test = split_data(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]: [0.52668244997625446, 0.69899092361566229, 0.53967745076214657, 0.9999985694885254, 0, 0, 0.7058823529411765, 0.875, 0.16666666666666666, 0.3333333333333333, 6.204848558361875, 8.233151896511865, 0.659789269855249, 0.7876718705275318, 1.845826690498331, 2.538973871058276, 0.7058823529411765, 0.16666666666666666, 0.6541370794030843, 1.845826690498331]\n",
      "X_train_scaled[0]: [ 1.99951746  3.38860009  0.59187768  1.030703   -0.06553302 -0.08412156\n",
      "  1.59813406  2.39367351  0.64550426  3.14105495  2.54419379  3.8748521\n",
      "  2.64426243  3.43104137  1.28918164  2.87152386  0.47113111 -0.02697961\n",
      "  1.00714807  0.29933199]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_scaled = StandardScaler().fit_transform(X_train)\n",
    "X_test_scaled = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "print('X_train[0]:', X_train[0])\n",
    "print('X_train_scaled[0]:', X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
    "         # \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\",\n",
    "         \"Neural Net 1\", \"Neural Net 0.001\", \"Neural Net 0.0001\", \"Neural Net 0.00001\",\n",
    "         \"AdaBoost Decision Tree\", \"AdaBoost Random Forest\",\n",
    "         \"Naive Bayes\",\n",
    "         \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(10),\n",
    "    SVC(kernel=\"linear\", C=100),\n",
    "    SVC(gamma=2, C=100),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=20),\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1),\n",
    "    MLPClassifier(alpha=1), MLPClassifier(alpha=0.001), MLPClassifier(alpha=0.0001),\n",
    "    MLPClassifier(alpha=0.00000001),\n",
    "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=30), n_estimators=100, learning_rate=1.5, algorithm=\"SAMME\"),\n",
    "    AdaBoostClassifier(RandomForestClassifier(n_estimators=1000, random_state=42, n_jobs=-1), n_estimators=1000, random_state=42),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "\n",
      "Writing results to \"answer.txt\".\n",
      "\n",
      "The results are written to \"answer.txt\".\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.78      0.75       509\n",
      "          1       0.75      0.69      0.72       491\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1000\n",
      " \n",
      "\n",
      "'KNeighborsClassifier' object has no attribute 'feature_importances_'\n",
      "Linear SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.72      0.73       509\n",
      "          1       0.72      0.74      0.73       491\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1000\n",
      " \n",
      "\n",
      "'SVC' object has no attribute 'feature_importances_'\n",
      "RBF SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.81      0.74       509\n",
      "          1       0.76      0.61      0.67       491\n",
      "\n",
      "avg / total       0.72      0.71      0.71      1000\n",
      " \n",
      "\n",
      "'SVC' object has no attribute 'feature_importances_'\n",
      "Decision Tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.65      0.69       509\n",
      "          1       0.68      0.76      0.72       491\n",
      "\n",
      "avg / total       0.71      0.70      0.70      1000\n",
      " \n",
      "\n",
      "[ 0.          0.003485    0.0050953   0.96655401  0.          0.\n",
      "  0.00529203  0.00206518  0.          0.          0.          0.\n",
      "  0.00769967  0.          0.          0.          0.00425276  0.\n",
      "  0.00555605  0.        ]\n",
      "Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.71      0.72       509\n",
      "          1       0.71      0.74      0.72       491\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1000\n",
      " \n",
      "\n",
      "[  2.23028420e-02   3.44559839e-02   2.82775339e-02   8.12409156e-01\n",
      "   6.47202194e-04   1.21819251e-03   7.91782685e-03   8.81578468e-03\n",
      "   5.77331193e-03   7.71443146e-03   5.67533780e-03   4.52313799e-03\n",
      "   6.90970820e-03   8.69289010e-03   5.99776071e-03   7.77589377e-03\n",
      "   9.73846487e-03   6.10369992e-03   9.18182249e-03   5.86901914e-03]\n",
      "Neural Net 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.74      0.74       509\n",
      "          1       0.73      0.72      0.72       491\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1000\n",
      " \n",
      "\n",
      "'MLPClassifier' object has no attribute 'feature_importances_'\n",
      "Neural Net 0.001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.74      0.73       509\n",
      "          1       0.73      0.71      0.72       491\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1000\n",
      " \n",
      "\n",
      "'MLPClassifier' object has no attribute 'feature_importances_'\n",
      "Neural Net 0.0001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73       509\n",
      "          1       0.72      0.72      0.72       491\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1000\n",
      " \n",
      "\n",
      "'MLPClassifier' object has no attribute 'feature_importances_'\n",
      "Neural Net 0.00001\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73       509\n",
      "          1       0.72      0.72      0.72       491\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1000\n",
      " \n",
      "\n",
      "'MLPClassifier' object has no attribute 'feature_importances_'\n",
      "AdaBoost Decision Tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.66      0.70       509\n",
      "          1       0.68      0.76      0.72       491\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1000\n",
      " \n",
      "\n",
      "[ 0.0017425   0.          0.0068378   0.96481151  0.          0.\n",
      "  0.00219426  0.0017425   0.00154889  0.          0.00553174  0.0017425\n",
      "  0.00216793  0.          0.          0.          0.00361407  0.\n",
      "  0.00600113  0.00206518]\n",
      "AdaBoost Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.71      0.72       509\n",
      "          1       0.71      0.74      0.72       491\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1000\n",
      " \n",
      "\n",
      "[  2.18351787e-02   3.28472108e-02   2.89818414e-02   8.16626548e-01\n",
      "   6.28709793e-04   1.19477075e-03   7.73952075e-03   8.40571396e-03\n",
      "   5.63393018e-03   8.02441868e-03   5.74515687e-03   4.32056626e-03\n",
      "   6.89348729e-03   8.25689262e-03   5.46849466e-03   7.43034386e-03\n",
      "   9.13103866e-03   6.08323338e-03   8.96930471e-03   5.78363872e-03]\n",
      "Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.71      0.72       509\n",
      "          1       0.71      0.73      0.72       491\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1000\n",
      " \n",
      "\n",
      "'GaussianNB' object has no attribute 'feature_importances_'\n",
      "QDA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.71      0.72       509\n",
      "          1       0.71      0.73      0.72       491\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1000\n",
      " \n",
      "\n",
      "'QuadraticDiscriminantAnalysis' object has no attribute 'feature_importances_'\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    predictions = clf.predict(X_test_scaled)\n",
    "    score = classification_report(y_test, predictions)\n",
    "    if name == 'Nearest Neighbors':\n",
    "        print_results_in_file(predictions, y_test)\n",
    "    print(score, '\\n')\n",
    "    try:\n",
    "        print(clf.feature_importances_)\n",
    "    except AttributeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
